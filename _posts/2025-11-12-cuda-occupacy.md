---
title: Understanding Occupancy in CUDA
by: hdimmfh
date: 2025-11-07 10:55:00 +0900
categories: [GPU, Cuda]
tags: [GPU, Cuda, Occupancy]
---

ðŸ”**Understanding Occupancy in CUDA**

## â‘  What Is Occupancy?

**Occupancy** refers to the ratio between the number of *active warps*
running on a Streaming Multiprocessor (SM) and the *maximum number of
warps* that the SM can theoretically support.

![Calculating Theoretical Occupacy](https://github.com/hdimmfh/blog-img-repo/blob/main/img/gpu/architecture/sm_block_thread_occupancy.png?raw=true)
*Figure 1. Theoretical Occupacy.*

> **Formula:**\
> Occupancy = `Active Warps per SM` / `Maximum Warps per SM`

It measures how effectively the GPU's parallel resources are being
utilized.

---

## â‘¡ Example

For instance, the NVIDIA A100 GPU can host up to `64 warps per SM`.\
If your kernel launches only `32 warps on each SM`, then:

> â–¶ï¸Ž Occupancy = 32 / 64 = 50%

That means only half of the SM's execution slots are actively used.

---

## â‘¢ Why It Matters

Higher occupancy generally improves **latency hiding**.\
While one warp waits for memory access, another can execute --- keeping
the SM busy.

However, occupancy is **not the sole performance indicator**.

-   âœ“ Higher occupancy â†’ better latency hiding and concurrency\
-   Too high occupancy â†’ less register/shared memory per thread,
    which can reduce efficiency

> âš ï¸ In practice, `60~80% occupancy` often yields the best performance --- not 100%.

---

## â‘£ What Limits Occupancy

| Factor | Description |
|--------|--------------|
| **Threads per block** | More threads per block â†’ fewer blocks can fit on the same SM |
| **Registers per thread** | More register usage â†’ fewer warps can be active simultaneously |
| **Shared memory per block** | Large shared memory per block â†’ fewer concurrent blocks per SM |

---

## â‘¤ Theoretical vs Achieved Occupancy

-   **Theoretical Occupancy**\
    Calculated from kernel launch parameters and SM hardware limits
    (e.g., threads, warps, blocks).\
    It assumes ideal conditions with all available resources used
    efficiently.

-   **Achieved Occupancy**\
    Measured after execution, showing how many warps were actually
    active during runtime.\
    Tools like `nvprof` or **Nsight Compute** can report this metric.

> âš ï¸ **Important Note:**\
> Theoretical occupancy always assumes the **maximum blocks per SM**.\
> Therefore, it is **usually higher than the achieved occupancy**
> measured in real runs.

---

## Summary

| Type | Description |
|------|--------------|
| **Occupancy** | Ratio of active to maximum warps per SM |
| **Theoretical Occupancy** | Estimated value based on hardware limits |
| **Achieved Occupancy** | Real value measured at runtime |
| **Purpose** | Evaluates GPU parallel efficiency and latency hiding capability |
| **Caution** | 100% occupancy â‰  best performance |

---

## References

-   NVIDIA CUDA Programming Guide, v12.4
-   Nsight Compute Metric: `sm__warps_active.avg.pct_of_peak_sustained_active`
-   NVIDIA CUDA Occupancy Calculator

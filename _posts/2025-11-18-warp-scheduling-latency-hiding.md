---
title: "NVIDIA GPU Warp Latency Hiding â€” How SM Partitions Actually Execute"
by: hdimmfh
date: 2025-11-18 01:40:00 +0900
categories: [GPU, Cuda]
tags: [Warp Scheduler, Latency Hiding, SM Partition, CUDA, Nsight]
---

ðŸ” **Understanding Warp Scheduling and Latency Hiding**

> â€œMany warps, four partitions â€” and only one warp per partition can run each cycle.â€  
> This post breaks down how SM partitions actually execute warps, how latency hiding really works, and why warp eligibility matters more than warp count.

---

## â‘  Overview

Modern NVIDIA GPUs rely on **massive concurrency** rather than making a single warp fast.  
On A100:

- 4 SM partitions
- 1 warp issued per partition per cycle
- Max 4 executing warps per SM

Active warps (16â€“64+) only increase the chance that at least one warp is *eligible* when others stall.

---

## â‘¡ SM Partition Architecture (A100)

A single SM is divided into 4 independent partitions, each containing:

- Warp Scheduler  
- Dispatch Unit  
- Register File slice  
- L0/L1 cache slice  
- Execution pipelines (FP32 / INT / LDST / Tensor)

Each partition selects its own warp every cycle:

```
Partition 0 â†’ warp A
Partition 1 â†’ warp B
Partition 2 â†’ warp C
Partition 3 â†’ warp D
```

<div style="text-align:center;">
  <img src="https://github.com/hdimmfh/blog-img-repo/blob/main/img/gpu/component/warp-scheduler.gif?raw=true" width="350">
  <br>
  <em>Figure 1. Warp-Scheduler: Selected Warp.</em>
</div>

---

## â‘¢ Warp States â€” Active, Eligible, Stalled, Selected

- Active :
    - Active = Eligible + Stalled + Selected
    - Warp is resident on the SM.
- Eligible â€” warp is ready to issue
- Stalled â€” warp is waiting (memory, dependency, pipeline)
- Selected â€” warp chosen by the scheduler this cycle

> âš ï¸ Note: \
> A Selected warp is also conceptually `a subset of eligible warps`, but separating it provides a clearer view of the full state distribution. A stalled warp does not leave the SM; it simply cannot issue.
---

## â‘£ Cache Line Hit vs Cache Line Divergence

1. Case1 : `Same` Cache Line Hit (Ideal)
    - 32 threads hit same line  
    - 1 transaction  
    - Zero contention

2. Case2 : `Different` Cache Line Hits  
Even when all accesses are hits:
- Multiple load requests  
- L1 port contention  
- Extra cycles  

This is effectively **microâ€‘serialization inside the cache**.

---

## â‘¤ Shared Memory: Why Bank Distribution Matters

![Bank Conflict](https://github.com/hdimmfh/blog-img-repo/blob/main/img/gpu/architecture/nvidia-sm-cache-memory-conflict.png?raw=true)
*Figure 2. Bank Conflict in Shared Memory per SM.*

1. Shared Memory (SMEM) is:
    - on-chip  
    - multi-banked  
    - extremely low latency  

2. When 32 threads hit `32 different banks`:
    - all banks operate in **parallel**  
    - zero cycles wasted  

Even if other warps hit the same bank, SMEM is so fast that crossâ€‘warp conflicts are rarely harmful.
> âœ”ï¸ Within a warp â†’ distribute accesses `across banks` \
> âœ”ï¸ Across warps â†’ `low risk`; SMEM is conflictâ€‘resistant

---

## â‘¥ How Latency Hiding Works

Latency hiding = swap out a `stalled warp` for a `ready(eligible) warp`.

When a warp stalls:
```
if (eligible warp exists):
    scheduler issues it â†’ latency hidden
else:
    no eligible warp â†’ wasted cycle
```

Requirement for full throughput on A100:  
> Eligible warps â‰¥ 4** (one per partition)

Warp refill is instant:
> Warp X finishes â†’ another becomes eligible.

---

## â‘¦ Timeline Example

1. Cycle 10  
    - Warp 3 selected  
    - Warp 7 **eligible**
    - Warp 12 stalled  
2. Cycle 11  
    - Warp 3 stalls  
    - Warp 7 **becomes selected**

> âš ï¸ Note: \
> If no warp is eligible â†’ partition idle â†’ SM underutilized.

---

## â‘§ Summary Table

| Concept | Meaning |
|--------|---------|
| Active Warp | Lives on SM |
| Eligible Warp | Ready to issue |
| Stalled Warp | Waiting |
| Selected Warp | Issued this cycle |
| Partition Rule | 1 warp per cycle |
| A100 Limit | 4 executing warps |
| Latency Hiding | Needs eligible warps |

---

## â‘¨ TL;DR

- A100 SM = 4 independent partitions  
- Each partition issues **one warp per cycle**  
- True execution parallelism = **4 warps per SM**  
- Occupancy increases the chance of eligible warps  
- Latency hiding = replacing stalled warps instantly  
- No eligible warp â†’ cycle wasted

Maintaining enough **eligible warps** is the real key to GPU performance.

---
title: Inside the GPU Stack
by: hdimmfh
date: 2025-11-04 20:47:00 +0900
categories: [GPU, Network]
tags: [PyTorch, CUDA, GDS, GPU, DeepLearning]
---

üîç **Understanding the Stack: PyTorch ‚Üí (CUDA / GDS) ‚Üí GPU**

When people say ‚ÄúPyTorch runs on GPU,‚Äù it‚Äôs only partly true.  
In reality, several layers cooperate to move data and execute computation efficiently.

---

## ‚ë† PyTorch ‚Äî The Orchestrator

PyTorch never touches GPU hardware directly.  
It defines what operations to run and where to run them, then calls CUDA APIs internally.

```python
x = x.to("cuda")  # calls cudaMemcpy()
y = torch.mm(x, x.T)  # launches cuBLAS kernel
```

PyTorch decides the logic; CUDA executes it.

---

## ‚ë° CUDA ‚Äî The Executor

CUDA (Compute Unified Device Architecture) is NVIDIA‚Äôs runtime that manages GPU memory and launches kernels.  
It handles:

- Memory allocation (`cudaMalloc`)
- Data transfer (`cudaMemcpy`)
- Kernel launch (`cudaLaunchKernel`)
- Stream synchronization

CUDA translates PyTorch‚Äôs high-level operations into GPU instructions.

---

## ‚ë¢ GPU ‚Äî The Worker

The GPU executes kernels scheduled by CUDA.  
It reads data from its VRAM, performs matrix ops, and writes back results.  
It never acts on its own ‚Äî every action begins with a CUDA command.

---

## ‚ë£ GDS (GPUDirect Storage) ‚Äî Direct Data Path

Traditionally, data flows like this:

```
NVMe SSD ‚Üí CPU RAM ‚Üí GPU VRAM
```

With **GPUDirect Storage**, it becomes:

```
NVMe SSD ‚Üí GPU VRAM
```

No CPU memory copy ‚Äî only a control signal from the CPU (`cuFileRead()`),  
then DMA engines move data directly between storage and GPU memory.  
The CPU initiates the command, but the transfer bypasses system memory entirely.

---

## ‚ë§ Stack Flow

- `PyTorch ‚Üí CUDA ‚Üí GPU ‚Üí GDS`

| Layer | Role |
| ------ | ------ |
| PyTorch | Defines operations, calls CUDA |
| CUDA | Manages memory, launches GPU kernels |
| GPU | Executes computations in parallel |
| GDS | Streams data from NVMe directly to GPU VRAM |

---

## In One Line

‚ë† PyTorch tells CUDA what to do,  
‚ë° CUDA tells the GPU how to do it,  
‚ë¢ the GPU performs the work,  
‚ë£ and GDS feeds data straight from storage to GPU memory.

---
<br/>
<span style="color:#999999">
    *Originally posted on [Tistory](https://hdimmfh.tistory.com/62)* ‚ú®
</span>

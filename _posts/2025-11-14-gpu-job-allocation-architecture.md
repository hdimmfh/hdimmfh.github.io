---
title: "MPS vs MIG vs MxGPU â€” Modern GPU Virtualization Explained"
by: hdimmfh
date: 2025-11-14 00:20:00 +0900
categories: [GPU, GPU Virtualization]
tags: [MPS, MIG, MxGPU, CUDA, ROCm]
---

ðŸ”**Understanding Modern GPU Virtualization**

> â€œOne GPU, many jobs â€” but not all sharing is the same.â€ \
> In this post, weâ€™ll explore how `cVIDIA MPS`, `NVIDIA MIG`, and `AMD MxGPU` differ in design, purpose, and execution model.

---

## â‘  Overview

Modern GPUs are no longer single-user accelerators.  
They can now be **shared across multiple processes or even multiple virtual machines**, thanks to technologies like:

- MPS (Multi-Process Service) â€” software-level GPU sharing for CUDA processes  
- MIG (Multi-Instance GPU) â€” hardware-level partitioning on Ampere+ GPUs  
- MxGPU (Multiuser GPU) â€” AMDâ€™s SR-IOVâ€“based GPU virtualization for ROCm environments

---

## â‘¡ MPS â€” Multi-Process Service

`MPS` allows multiple CUDA processes (typically MPI ranks) to share a single GPU concurrently. It replaces CUDAâ€™s per-process context scheduling with a single shared context, reducing overhead.

![NVIDIA MPS Architecture](https://github.com/hdimmfh/blog-img-repo/blob/main/img/gpu/architecture/nvidia-mps-architecture.png?raw=true)
*Figure 1. NVIDIA MPS Architecture.*

âœ”ï¸ Key traits
- Type: Software-level, runtime multiplexing  
- Scope: Multiple processes of the *same job* (cooperative)  
- Architecture: Clientâ€“server (via `nvidia-cuda-mps-server`)  
- Benefit: Better utilization, lower context-switch overhead  
- Limitation: Single user per GPU (unless Volta+ `multiuser-server` mode)  

âœ”ï¸ Memory behavior
- Pre-Volta: Shared GPU virtual address space â†’ out-of-range writes could overwrite other clients  
- Volta+: Fully isolated address space per client  

âœ”ï¸ Best for
- Multi-process CUDA or MPI workloads where each process underutilizes the GPU.

---

## â‘¢ MIG â€” Multi-Instance GPU

`MIG` (introduced with NVIDIA Ampere) enables true hardware-level GPU partitioning. Each partition, or GPU instance, has dedicated compute cores, memory, and cache slices.

![NVIDIA MIG Architecture](https://github.com/hdimmfh/blog-img-repo/blob/main/img/gpu/architecture/nvidia-mig-architecture.jpg?raw=true)
*Figure 2. NVIDIA MIG Architecture.*

âœ”ï¸ Key traits
- Type: Hardware-level virtualization  
- Scope: Independent GPU partitions per job or container  
- Isolation:** Strong â€” each MIG instance behaves like a separate GPU  
- Management: Controlled via `nvidia-smi mig` or Kubernetes device plugin  
- Compatibility: Requires A100 or newer GPUs  

âœ”ï¸ Memory & performance
- No shared VRAM region; each instance has fixed VRAM capacity.  
- Fault isolation between MIG instances.  
- No context sharing or inter-instance communication.

âœ”ï¸ Best for
- Multi-tenant environments (Kubernetes, Slurm) where **strict isolation** and **predictable QoS** are required.

---

## â‘£ MxGPU â€” AMDâ€™s Multiuser GPU

`MxGPU (Multiuser GPU)` is AMDâ€™s SR-IOVâ€“based GPU virtualization solution.Unlike NVIDIAâ€™s MIG or MPS, itâ€™s designed from the start for virtual machines (VMs).

![AMD MxGPU Architecture](https://github.com/hdimmfh/blog-img-repo/blob/main/img/gpu/architecture/amd-sr-iov-mxgpu-architecture.jpg?raw=true)
*Figure 3. AMD SR-IOV MxGPU Architecture.*

âœ”ï¸ Key traits
- Type: Hardware-assisted virtualization (SR-IOV)  
- Scope: Multiple VMs share one physical GPU via virtual functions (VFs)  
- Platform: ROCm + AMD Instinct MI-series or Radeon Pro GPUs  
- Isolation: Each VF has independent memory and scheduler  
- Driver: `amdgpu-pro` with SR-IOV support  

âœ”ï¸ Integration
- Works seamlessly with **KVM**, **VMware**, and **Proxmox**.  
- Each VF appears as a discrete GPU device to the guest OS.  
- Supports ROCm/HIP workloads on supported hardware.

âœ”ï¸ Best for
- Cloud and VDI environments where **GPU passthrough per VM** is needed.

ðŸ’¡ What is SR-IOV?
> SR-IOV (Single Root I/O Virtualization) is a PCIe standard that allows a single physical device (like a GPU or NIC) to expose multiple Virtual Functions (VFs) to the system.  
>
>Each VF acts as an independent device that can be directly assigned to a virtual machine or container â€” enabling hardware-level GPU sharing with minimal overhead.

---

## â‘¤ Comparison Summary

| Feature | **MPS** | **MIG** | **MxGPU** |
|----------|----------|----------|------------|
| Level | Software | Hardware | Hardware (SR-IOV) |
| Vendor | NVIDIA | NVIDIA | AMD |
| Architecture | Clientâ€“Server | Partitioned SM & VRAM | Virtual Functions (VFs) |
| Isolation | Weak (Pre-Volta)</br> â†’ Strong (Volta+) | Strong | Strong |
| Use Case | Multi-process job sharing | Multi-tenant GPU isolation | GPU sharing across VMs |
| CUDA/ROCm | CUDA only | CUDA only | ROCm only |
| Scheduling | Cooperative | Dedicated | Hardware-assisted |
| Typical Env | HPC clusters, MPI | Data centers, Kubernetes | Cloud, Virtualization hosts |

---

## â‘¥ Practical Notes

- **MPS** â‰ˆ â€œmany MPI ranks, one GPUâ€  
- **MIG** â‰ˆ â€œmany GPUs inside one GPUâ€  
- **MxGPU** â‰ˆ â€œone GPU shared across many VMsâ€

> âš ï¸ These technologies are **mutually exclusive** on a single device.  
> You cannot enable MIG and MPS on the same GPU simultaneously.

---

## â‘¦ TL;DR

| Goal | Recommended Tech |
|------|------------------|
| Maximize GPU utilization for MPI jobs | **MPS** |
| Strong isolation between tenants | **MIG** |
| Virtualization and VM-level GPU sharing | **MxGPU** |

---

## ðŸ“š References

- [NVIDIA MPS Documentation](https://docs.nvidia.com/deploy/mps/index.html)  
- [NVIDIA MIG User Guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html)  
- [AMD MxGPU (SR-IOV) Overview](https://www.amd.com/en/technologies/sr-iov.html)  
- [ROCm Documentation](https://rocmdocs.amd.com/en/latest/)  
